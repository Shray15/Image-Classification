{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Necessary Libararies"
      ],
      "metadata": {
        "id": "EOFOQAqLGTQf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPs_yfPKEeKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c64009-6944-42d0-eadf-c762051a9c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python==3.4.2.17\n",
            "  Downloading opencv_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (25.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0 MB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==3.4.2.17) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.6.0.66\n",
            "    Uninstalling opencv-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-4.6.0.66\n",
            "Successfully installed opencv-python-3.4.2.17\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-contrib-python==3.4.2.17\n",
            "  Downloading opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6 MB 102 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==3.4.2.17) (1.21.6)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.6.0.66\n",
            "    Uninstalling opencv-contrib-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-contrib-python-4.6.0.66\n",
            "Successfully installed opencv-contrib-python-3.4.2.17\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#SIFT algorithm is patented and is excluded in the latest configuration of opencv, so an older version of opencv was used to implement it.\n",
        "!pip3 install opencv-python==3.4.2.17\n",
        "!pip3 install opencv-contrib-python==3.4.2.17\n",
        "import cv2\n",
        "\n",
        "#This step is necessary as it provides access to the google drive where the dataset is stored.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Visualisation"
      ],
      "metadata": {
        "id": "mq_W9yS3Iamu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A list to store the dimensions of each image of the dataset.\n",
        "image_dims = []\n",
        "#Path to the dataset\n",
        "img_folder = '/content/gdrive/My Drive/BigCats2'                               \n",
        "animals = ['/Leopard', '/Cheetah', '/Jaguar', '/Lion', '/Tiger']\n",
        "choice_animals = int(input('What animal picture samples would you like to visualise?\\nEnter   0 - Leopard\\n \\t1 - Cheetah\\n \\t2 - Jaguar\\n \\t3 - Lion\\n \\t4 - Tiger\\n \\t5 - One sample for each of the above\\n'))\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "for i in range(5):\n",
        "    if choice_animals == 0:\n",
        "        file = random.choice(os.listdir(img_folder + animals[0]))\n",
        "        image_path = os.path.join(img_folder + animals[0], file)\n",
        "    if choice_animals == 1:\n",
        "        file = random.choice(os.listdir(img_folder + animals[1]))\n",
        "        image_path = os.path.join(img_folder + animals[1], file)\n",
        "    if choice_animals == 2:\n",
        "        file = random.choice(os.listdir(img_folder + animals[2]))\n",
        "        image_path = os.path.join(img_folder + animals[2], file)\n",
        "    if choice_animals == 3:\n",
        "        file = random.choice(os.listdir(img_folder + animals[3]))\n",
        "        image_path = os.path.join(img_folder + animals[3], file)\n",
        "    if choice_animals == 4:\n",
        "        file = random.choice(os.listdir(img_folder + animals[4]))\n",
        "        image_path = os.path.join(img_folder + animals[4], file)\n",
        "    if choice_animals == 5:\n",
        "        file = random.choice(os.listdir(img_folder + animals[i]))\n",
        "        image_path = os.path.join(img_folder + animals[i], file)\n",
        "    img = mpimg.imread(image_path)\n",
        "    ax=plt.subplot(1, 5, i+1)\n",
        "    ax.title.set_text(file)\n",
        "    plt.imshow(img)         #Plottiing sample images\n",
        "\n",
        "\n",
        "for dir1 in os.listdir(img_folder):\n",
        "    for file in os.listdir(os.path.join(img_folder, dir1)):       \n",
        "        image_path = os.path.join(img_folder, dir1, file)\n",
        "        image_dims.append(cv2.imread(image_path).shape)\n",
        "\n",
        "max_dim = max(image_dims)   #Finding the largest dimension from all the image dimensions\n",
        "min_dim = min(image_dims)   #Finding the smallest dimension from all the image dimensions\n",
        "print('Biggest image in the dataset is of dimension:' + str(max_dim))\n",
        "print('Smallest image in the dataset is of dimension:' + str(min_dim))"
      ],
      "metadata": {
        "id": "w2pPEgAEIMnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Transformation"
      ],
      "metadata": {
        "id": "s-bwCC0wUuuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_choice = int(input('Which method would you like to use on the data?\\n\\t0 - Nothing\\n\\t1 - SIFT\\n\\t2 - MDS\\n'))\n",
        "IMG_HEIGHT = 400    #Declaring the dimensions of the images to be resized.\n",
        "IMG_WIDTH = 500\n",
        "\n",
        "#Creation of SIFT function if the user opts to use SIFT\n",
        "if data_choice == 1:\n",
        "  sift = cv2.xfeatures2d.SIFT_create(8)\n",
        "\n",
        "#Creating a dataset by importing all the images and their class labels, and converting the images to a numeric array.\n",
        "def create_dataset(img_folder):\n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path = os.path.join(img_folder, dir1,  file)\n",
        "            if data_choice == 0 or data_choice == 2:\n",
        "              image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
        "              image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_NEAREST)     #Resizing the image\n",
        "              image = np.array(image)                                                                   #Coverting the image to an array\n",
        "              image = image.astype('float32')\n",
        "              image /= 255                                                                              #Scaling the Values by dividing array with channel value range\n",
        "            elif data_choice == 1:\n",
        "              image = cv2.imread(image_path, cv2.COLOR_BGR2GRAY)\n",
        "              image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_NEAREST)     #Resizing the image\n",
        "              kp, des = sift.detectAndCompute(image, None)                                              #SIFT function computes the key points and descriptors                                                           \n",
        "              #Making a key point array\n",
        "              image_temp = []\n",
        "              for i in range(8):\n",
        "                image_temp.append([kp[i].pt[0], kp[i].pt[1]])\n",
        "              image = image_temp\n",
        "\n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "    return img_data_array, class_name\n",
        "\n",
        "img_data, class_name = create_dataset('/content/gdrive/My Drive/BigCats2')\n",
        "\n",
        "#Feature extraction, Dimension reduction and no modification:\n",
        "if data_choice == 0:\n",
        "  img_data = np.array(img_data, np.float32).reshape(170, 600000)                #Reshaping array dimensions\n",
        "elif data_choice == 1:\n",
        "  img_data = np.array(img_data, np.float32).reshape(170, 16)                    #Reshaping array dimensions\n",
        "elif data_choice == 2:\n",
        "  img_data = np.array(img_data, np.float32).reshape(170, 600000)                #Reshaping array dimensions\n",
        "  dm = distance_matrix(img_data, img_data)                                      #Calculating the dissimilarity matrix\n",
        "  mds = MDS(n_components = 2, random_state = 42)                                    #Creating MDS model\n",
        "  img_data = mds.fit_transform(dm)                                              #Scaling the image data to 2 dimensions\n",
        "\n",
        "#Encoding class labels\n",
        "le = preprocessing.LabelEncoder()\n",
        "cats_encoded = le.fit_transform(class_name)\n"
      ],
      "metadata": {
        "id": "mc_ic5thac83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_choice = int(input('Which classification model would you like to use?\\n\\t0 - Random Forest\\n\\t1 - SVM \\n\\t2 - K Nearest Neighbours\\n'))\n",
        "\n",
        "#Splitting Data for Training and Testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(img_data, cats_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "if classification_choice == 0:\n",
        "  rfc = RandomForestClassifier(n_estimators = 16, max_depth = 8, criterion = \"gini\", random_state = 42)                 #Random Forest (RF) model creation\n",
        "  rfc.fit(X_train, y_train)                                                                                             #Training RF model\n",
        "  y_pred = rfc.predict(X_test)                                                                                          #Testing RF model\n",
        "  print('Accuracy of the Random Forest model was ' + str(accuracy_score(y_test, y_pred)*100))\n",
        "\n",
        "elif classification_choice == 1:\n",
        "  SVM = svm.SVC()                                                                                                       #Support Vector Machines (SVM) model creation\n",
        "  SVM.fit(X_train, y_train)                                                                                             #Training SVM model\n",
        "  y_pred = SVM.predict(X_test)                                                                                          #Testing SVM model\n",
        "  print('Accuracy of the SVM model was ' + str(accuracy_score(y_test, y_pred)*100))\n",
        "\n",
        "elif classification_choice == 2:\n",
        "  k_nn = KNeighborsClassifier(n_neighbors=31, weights='distance', p = 2, algorithm='auto')                              #K Nearest Neighbours (KNN) model creation\n",
        "  k_nn.fit(X_train, y_train)                                                                                            #Training KNN model\n",
        "  y_pred = k_nn.predict(X_test)                                                                                         #Testing KNN model\n",
        "  print('Accuracy of the K Nearest Neighbours model was ' + str(accuracy_score(y_test, y_pred)*100) + '% when K = 9')"
      ],
      "metadata": {
        "id": "34hm1mp2po3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Leave One Out Cross Validation"
      ],
      "metadata": {
        "id": "cV3tqt36iUh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loo = LeaveOneOut()                 #Leave-One-Out cross-validator\n",
        "loo.get_n_splits(img_data)\n",
        "acc = 0\n",
        "\n",
        "if classification_choice == 0:\n",
        "  for train_index, test_index in loo.split(img_data):\n",
        "      X_train, X_test = img_data[train_index], img_data[test_index]                                                   #Train and Test split for image data\n",
        "      y_train, y_test = cats_encoded[train_index], cats_encoded[test_index]                                           #Train and Test split for class labels\n",
        "      loov_model = RandomForestClassifier(n_estimators = 16, max_depth = 8, criterion = \"gini\", random_state = 42)    #RF model creation\n",
        "      loov = loov_model.fit(X_train, y_train)                                                                         #Training RF model\n",
        "      if loov.predict(X_test) == y_test:                                                                              #Testing the prediction against the actual value\n",
        "        acc += 1\n",
        "  print('Average accuracy of the Random Forest model in Leave One Out Crossvalidation: ' + str(acc/170))\n",
        "\n",
        "elif classification_choice == 1:\n",
        "  for train_index, test_index in loo.split(img_data):\n",
        "      X_train, X_test = img_data[train_index], img_data[test_index]                                                   #Train and Test split for image data\n",
        "      y_train, y_test = cats_encoded[train_index], cats_encoded[test_index]                                           #Train and Test split for class labels\n",
        "      loov_model = svm.SVC()                                                                                          #SVM model creation\n",
        "      loov = loov_model.fit(X_train, y_train)                                                                         #Training SVM model\n",
        "      if loov.predict(X_test) == y_test:                                                                              #Testing the prediction against the actual value\n",
        "        acc += 1\n",
        "  print('Average accuracy of the SVM model in Leave One Out Crossvalidation: ' + str(acc/170))\n",
        "\n",
        "elif classification_choice == 2:\n",
        "  for train_index, test_index in loo.split(img_data):\n",
        "      X_train, X_test = img_data[train_index], img_data[test_index]                                                   #Train and Test split for image data\n",
        "      y_train, y_test = cats_encoded[train_index], cats_encoded[test_index]                                           #Train and Test split for class labels\n",
        "      loov_model = KNeighborsClassifier(n_neighbors = 31, weights = 'distance', p = 2, algorithm = 'auto')                                                              #KNN model creation\n",
        "      loov = loov_model.fit(X_train, y_train)                                                                         #Training KNN model\n",
        "      if loov.predict(X_test) == y_test:                                                                              #Testing the prediction against the actual value\n",
        "        acc += 1\n",
        "  print('Average accuracy of the K Nearest Neighboours model in Leave One Out Crossvalidation: ' + str(acc/170))"
      ],
      "metadata": {
        "id": "lkpHfN-vB57A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble Learning"
      ],
      "metadata": {
        "id": "XdtJk0ZyTVj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "En_RF = RandomForestClassifier(n_estimators = 16, max_depth = 8, criterion = \"gini\", random_state = 42)             #RF model creation\n",
        "En_SVM = svm.SVC()                                                                                                  #SVM model creation\n",
        "En_KNN = KNeighborsClassifier(n_neighbors = 31, weights = 'distance', p = 2, algorithm = 'auto')                    #KNN model creation\n",
        "\n",
        "\n",
        "loo = LeaveOneOut()                                                                                                 #Leave-One-Out cross-validator\n",
        "loo.get_n_splits(img_data)\n",
        "\n",
        "total_accuracies = []\n",
        "for train_index, test_index in loo.split(img_data):\n",
        "    X_train, X_test = img_data[train_index], img_data[test_index]                                                   #Train and Test split for image data\n",
        "    y_train, y_test = cats_encoded[train_index], cats_encoded[test_index]                                           #Train and Test split for class labels\n",
        "\n",
        "    #Training\n",
        "    En_RF.fit(X_train, y_train)\n",
        "    En_SVM.fit(X_train, y_train)\n",
        "    En_KNN.fit(X_train, y_train)\n",
        "\n",
        "    #Manual Ensemble\n",
        "    En_RF_pred = En_RF.predict(X_test)\n",
        "    En_SVM_pred = En_SVM.predict(X_test)\n",
        "    En_KNN_pred = En_KNN.predict(X_test)\n",
        "\n",
        "    accuracies = 9\n",
        "    for index in range(len(y_test)):\n",
        "        buffer_1 = En_RF_pred[index]  \n",
        "        buffer_2 = En_SVM_pred[index] \n",
        "        buffer_3 = En_KNN_pred[index]   \n",
        "        #Voting\n",
        "        vote = 0\n",
        "        if(buffer_1 ==  y_test[index]):\n",
        "            vote += 1\n",
        "        if(buffer_2 ==  y_test[index]):\n",
        "            vote += 1\n",
        "        if(buffer_3 ==  y_test[index]):\n",
        "            vote += 1\n",
        "        if(vote >= 2):\n",
        "            accuracies = 1\n",
        "        else: \n",
        "            accuracies = 0\n",
        "\n",
        "    total_accuracies.append(accuracies)\n",
        "\n",
        "\n",
        "accuracy = sum(total_accuracies) / 170\n",
        "print('Ensemble: ' + str(accuracy))"
      ],
      "metadata": {
        "id": "RUfH94G_TVI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clustering"
      ],
      "metadata": {
        "id": "Knuf2ZCMoX--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting Data for Training and Testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(img_data, cats_encoded, test_size=0.2, random_state=42)\n",
        "kmeans = KMeans(n_clusters = 3)                  #K-Means model creation\n",
        "X = metrics.pairwise_distances(X_test)           #Pairwise distance computation\n",
        "y_pred = kmeans.fit_predict(X)                   #Prediction of class labels\n",
        "SC = metrics.silhouette_score(X, y_pred)         #Computation of Silhouette score\n",
        "print('Silhouette score for the K Means model: ' + str(SC))"
      ],
      "metadata": {
        "id": "ZASBOUVZoSDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}